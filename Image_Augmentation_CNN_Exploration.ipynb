{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Histopathologic Cancer Detection</H2>\n",
    "<br>Identify metastatic tissue in histopathologic scans of lymph node sections \n",
    "by Image Processing and Convolutional Neural Networks</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Introduction</H3>\n",
    "<br>This kernel focuses on evaluation of three different types of popular image augmentation technics and explore how they can affect the classification accuracy of Convolutional Neural Networks</br>\n",
    "<br></br>\n",
    "\n",
    "<H5>Data:</H5>\n",
    "<br>PatchCamelyon (PCam) benchmark dataset</br>\n",
    "<br>278,000 scans of lymph node sections with labels (cancer/non-cancer)</br>\n",
    "<br></br>\n",
    "\n",
    "<H5>Goal:</H5>\n",
    "<br>Implement different image augmentation algoritms for processing the training image to optimize the CNN model performance</br>\n",
    "<br></br>\n",
    "\n",
    "<H5>Content:</H5>\n",
    "<br>The primary content of this kernel consists of:</br>\n",
    "<ol>\n",
    "    <li>Image Cleaning/Prepocessing</li>\n",
    "    <li>Image Augmentations Crux</li>\n",
    "    <li>Convolutional Neural Networks (CNN)</li>\n",
    "    <li>Model Evaluation</li>\n",
    "    <li>Conclusion</li>\n",
    "</ol> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Image Cleaning/Prepocessing</H3>\n",
    "<br>One of the most important reasons for prepocessing the input images is to help reduce the training error</br>\n",
    "<br>In this section, re-balancing the training and testing images with equal number in each class(label) and removing outliers (defective images) are preformed</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the required packages\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(101)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Convolution1D, concatenate, SpatialDropout1D, GlobalMaxPool1D, GlobalAvgPool1D, Embedding, \\\n",
    "    Conv2D, SeparableConv1D, Add, BatchNormalization, Activation, GlobalAveragePooling2D, LeakyReLU, Flatten\n",
    "from keras.layers import Dense, Input, Dropout, MaxPooling2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, \\\n",
    "    Lambda, Multiply, LSTM, Bidirectional, PReLU, MaxPooling1D\n",
    "from keras.layers.pooling import _GlobalPooling1D\n",
    "from keras.losses import mae, sparse_categorical_crossentropy, binary_crossentropy\n",
    "from keras.models import Model\n",
    "from keras.applications.nasnet import NASNetMobile, NASNetLarge, preprocess_input\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the base directory (original training folder)\n",
    "base_tile_dir = 'histopathologic-cancer-detection/train/'\n",
    "\n",
    "#Merge the label csv and training images' labels\n",
    "df = pd.DataFrame({'path': glob(os.path.join(base_tile_dir,'*.tif'))})\n",
    "df['id'] = df.path.map(lambda x: x.split('/')[1].split('\\\\')[1].split('.')[0])\n",
    "labels = pd.read_csv(\"histopathologic-cancer-detection/train_labels.csv\")\n",
    "df_whole = df.merge(labels, on = \"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H5>Removing outliers:</H5>\n",
    "<br>In the training set, there are 6 completely white and 1 completely black images that will undermine the training process. Therefore they should be removed</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove outliers \n",
    "#All white\n",
    "whiteList = ['f6f1d771d14f7129a6c3ac2c220d90992c30c10b',\n",
    "             '9071b424ec2e84deeb59b54d2450a6d0172cf701', \n",
    "             'c448cd6574108cf14514ad5bc27c0b2c97fc1a83', \n",
    "             '54df3640d17119486e5c5f98019d2a92736feabc', \n",
    "             '5f30d325d895d873d3e72a82ffc0101c45cba4a8', \n",
    "             '5a268c0241b8510465cb002c4452d63fec71028a']\n",
    "\n",
    "#All black\n",
    "blackList = ['9369c7278ec8bcc6c880d99194de09fc2bd4efbe']\n",
    "\n",
    "#Remove outliers from training set\n",
    "for whiteId in whiteList:\n",
    "    df_whole = df_whole[df_whole['id'] != whiteId]\n",
    "\n",
    "for blackId in blackList:\n",
    "    df_whole = df_whole[df_whole['id'] != blackId]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H5>Re-balancing training/testing labels:</H5>\n",
    "<br>Since the original data consists of 60 / 40 split of negative to positive samples, here, 10000 samples for both 0 and 1 are selected randomly from training set to balance the labels</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Sampling of 10000 for both 0 and 1 cases\n",
    "SAMPLE_SIZE = 10000\n",
    "\n",
    "#Class 0\n",
    "df_0 = df_whole[df_whole['label'] == 0].sample(SAMPLE_SIZE, random_state = 101)\n",
    "#Class 1\n",
    "df_1 = df_whole[df_whole['label'] == 1].sample(SAMPLE_SIZE, random_state = 101)\n",
    "\n",
    "# Concat the dataframes\n",
    "df_data = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\n",
    "# Shuffle\n",
    "df_data = df_data.sample(frac=1).reset_index(drop=True)\n",
    "# View the numbers in each class\n",
    "# df_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Image Augmentations Crux</H3>\n",
    "<br>This section contains code for three different augmentations technics/filters:</br>\n",
    "<ol>\n",
    "  <li>Linear Blur and Sharp</li>\n",
    "  <li>Gaussian Blur</li>\n",
    "  <li>Random Whitening/Contrast</li>\n",
    "</ol> \n",
    "<br>The primary reason for using image augmentation is to avoid overfitting and generate new images for training</br>\n",
    "<br>But in our kernel, we try to use them to emphasize the features (in the center 86x86px) and reduce the noise (surrounding 5px) to see if these modifications can help generate better accuracy scores for CNN model</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Curx functions\n",
    "\n",
    "#Blur the surrounding 5px and sharp the inner 86px\n",
    "def blur_sharp(color):\n",
    "    #New imgae matrix placeholder\n",
    "    matrix = np.zeros((96,96), dtype=np.uint8)\n",
    "    R_new = color\n",
    "    \n",
    "    #Gaussian Blur Kernel on 96-86-96px\n",
    "    for i in range(1,5):\n",
    "        for j in range(1,95):\n",
    "            matrix[i,j] = np.uint8((np.int(R_new[i-1,j-1])/16 + np.int(R_new[i-1,j])/8 + np.int(R_new[i-1,j+1])/16 + \n",
    "                           np.int(R_new[i,j-1])/8 + np.int(R_new[i,j])/4 + np.int(R_new[i,j+1])/8 +\n",
    "                           np.int(R_new[i+1,j-1])/16 + np.int(R_new[i+1,j])/8 + np.int(R_new[i+1,j+1])/16))\n",
    "    for i in range(91,95):\n",
    "        for j in range(1,95):\n",
    "            matrix[i,j] = np.uint8((np.int(R_new[i-1,j-1])/16 + np.int(R_new[i-1,j])/8 + np.int(R_new[i-1,j+1])/16 + \n",
    "                           np.int(R_new[i,j-1])/8 + np.int(R_new[i,j])/4 + np.int(R_new[i,j+1])/8 +\n",
    "                           np.int(R_new[i+1,j-1])/16 + np.int(R_new[i+1,j])/8 + np.int(R_new[i+1,j+1])/16))\n",
    "    \n",
    "    for i in range(1,95):\n",
    "        for j in range(1,5):\n",
    "            matrix[i,j] = np.uint8((np.int(R_new[i-1,j-1])/16 + np.int(R_new[i-1,j])/8 + np.int(R_new[i-1,j+1])/16 + \n",
    "                           np.int(R_new[i,j-1])/8 + np.int(R_new[i,j])/4 + np.int(R_new[i,j+1])/8 +\n",
    "                           np.int(R_new[i+1,j-1])/16 + np.int(R_new[i+1,j])/8 + np.int(R_new[i+1,j+1])/16))\n",
    "    \n",
    "    for i in range(1,95):\n",
    "        for j in range(91,95):\n",
    "            matrix[i,j] = np.uint8((np.int(R_new[i-1,j-1])/16 + np.int(R_new[i-1,j])/8 + np.int(R_new[i-1,j+1])/16 + \n",
    "                           np.int(R_new[i,j-1])/8 + np.int(R_new[i,j])/4 + np.int(R_new[i,j+1])/8 +\n",
    "                           np.int(R_new[i+1,j-1])/16 + np.int(R_new[i+1,j])/8 + np.int(R_new[i+1,j+1])/16))\n",
    "    \n",
    "    #High-pass sharpening\n",
    "    for i in range(4,91):\n",
    "        for j in range(4,91):\n",
    "            matrix[i,j] = np.uint8(1/8*(np.int(R_new[i-1,j-1])*-1 + np.int(R_new[i-1,j])*-1 + np.int(R_new[i-1,j+1])*-1 + \n",
    "                           np.int(R_new[i,j-1])*-1 + np.int(R_new[i,j])*16 + np.int(R_new[i,j+1])*-1 +\n",
    "                           np.int(R_new[i+1,j-1])*-1 + np.int(R_new[i+1,j])*-1 + np.int(R_new[i+1,j+1])*-1))\n",
    "    \n",
    "    #plt.figure(figsize=(10,10))\n",
    "    final = matrix[1:95,1:95]\n",
    "    #plt.imshow(final) \n",
    "    return final\n",
    "\n",
    "\n",
    "#Weighted Averaging filter (Gassian Filter)\n",
    "def weighted_filter(color, b):\n",
    "    matrix = np.zeros((96,96), dtype=np.uint8)\n",
    "    R_new = color\n",
    "    for i in range(1,95):\n",
    "        for j in range(1,95):\n",
    "            matrix[i,j] = np.uint8(1/(1+b)/(1+b)*(np.int(R_new[i-1,j-1])*1 + np.int(R_new[i-1,j])*b + np.int(R_new[i-1,j+1])*1 + \n",
    "                           np.int(R_new[i,j-1])*b + np.int(R_new[i,j])*b*b + np.int(R_new[i,j+1])*b +\n",
    "                           np.int(R_new[i+1,j-1])*1 + np.int(R_new[i+1,j])*b + np.int(R_new[i+1,j+1])*1))\n",
    "    #plt.figure(figsize=(10,10))\n",
    "    final = matrix[1:95,1:95]\n",
    "    #plt.imshow(final) \n",
    "    return final\n",
    "    \n",
    "\n",
    "#Brightness/Contrast adjustment\n",
    "def bright_contrast(input_img): \n",
    "    b,g,r = cv2.split(input_img)\n",
    "    #Resize to be 94*94 \n",
    "    b = b[1:95,1:95]\n",
    "    g = g[1:95,1:95]\n",
    "    r = r[1:95,1:95]\n",
    "    rgb_img = cv2.merge([r,g,b])\n",
    "    RANDOM_BRIGHTNESS = 64  # range (0-100), 0=no change\n",
    "    RANDOM_CONTRAST = 7   # range (0-100), 0=no change\n",
    "    \n",
    "    # Random brightness\n",
    "    br = random.randint(-RANDOM_BRIGHTNESS, RANDOM_BRIGHTNESS) / 100.\n",
    "    rgb_img = np.uint8(rgb_img + br)\n",
    "        \n",
    "    # Random contrast\n",
    "    cr = 1.0 + random.randint(-RANDOM_CONTRAST, RANDOM_CONTRAST) / 100.\n",
    "    rgb_img = np.uint8(rgb_img * cr)\n",
    "    \n",
    "    #plt.figure(figsize=(10,10))\n",
    "    #plt.imshow(rgb_img)\n",
    "    return rgb_img\n",
    "\n",
    "#Apply the three different filters above to input image\n",
    "def apply(img, function):\n",
    "    R_initial = img[:,:,0]\n",
    "    G_initial = img[:,:,1]\n",
    "    B_initial = img[:,:,2]\n",
    "    \n",
    "    #Apply function\n",
    "    if (function == 'weighted_filter'):\n",
    "        R_final = weighted_filter(R_initial, 2)\n",
    "        G_final = weighted_filter(G_initial, 2)\n",
    "        B_final = weighted_filter(B_initial, 2)\n",
    "    elif (function == 'blur_sharp'):\n",
    "        R_final = blur_sharp(R_initial)\n",
    "        G_final = blur_sharp(G_initial)\n",
    "        B_final = blur_sharp(B_initial)\n",
    "    elif (function == 'bright_contrast'):\n",
    "        img_final = bright_contrast(img)\n",
    "        return img_final\n",
    "    \n",
    "    img_final = np.dstack((R_final, G_final))\n",
    "    img_final = np.dstack((img_final, B_final))\n",
    "    #plt.figure(figsize=(10,10))\n",
    "    #plt.imshow(img_final)\n",
    "    return img_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examples:\n",
    "img = cv2.imread('histopathologic-cancer-detection/train/d42e09bc5560bb88ef86b34f58e0657381455fa2.tif')\n",
    "case1 = apply(img, 'weighted_filter')\n",
    "case2 = apply(img, 'blur_sharp')\n",
    "case3 = apply(img, 'bright_contrast')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H5>Results:</H5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/linear_filter.png\" alt=\"Linear Filter\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/gaussian_blur.png\" alt=\"Gaussian Blur\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/w_c.png\" alt=\"Random Whitening/Contrast\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Convolutional Neural Networks (CNN)</H3>\n",
    "<br>This section contains code for creating the pipeline of CNN machine learning, which consists of:</br>\n",
    "<ol>\n",
    "  <li>Split Train and Test Sets</li>\n",
    "  <li>Copy Images to New Directory</li>\n",
    "  <li>Build CNN Model</li>\n",
    "  <li>Save Model Locally</li>\n",
    "</ol> \n",
    "<br>Note: The parameters for building CNN Model is the same for all three different runs with different training images:</br>\n",
    "<ol>\n",
    "  <li>Original Image</li>\n",
    "  <li>Augmented Image 1 (Linear Filter)</li>\n",
    "  <li>Augmented Image 2 (Guassian Blur + White/Contrast)</li>\n",
    "</ol> \n",
    "<br>To run the code for three different datasets, you will need to change the names for making dictory/saving the model and run code to apply filters to the training images (will explain below)</br>\n",
    "<br>In my code (not shown), I set the original dataset directory to <b>base_dir</b> and <b>augement_1</b> for linear filter, <b>augement_2</b> for the other</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test\n",
    "# stratify=y creates a balanced validation set.\n",
    "y = df_data['label'] #response variable\n",
    "\n",
    "#Split by 9(df_train)/1(df_val)\n",
    "df_train, df_val = train_test_split(df_data, test_size=0.10, random_state=101, stratify=y)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)\n",
    "\n",
    "\n",
    "### Create directory separated from the entire training set\n",
    "'''\n",
    "Structure:\n",
    "    \n",
    "- base_dir  <------------------------ The name should be changed when running different training sets\n",
    "    - train_dir\n",
    "        - no_tumor_tissue\n",
    "        - has_tumor_tissue\n",
    "    - val_dir\n",
    "        - no_tumor_tissue\n",
    "        - has_tumor_tissue\n",
    "'''\n",
    "\n",
    "base_dir = 'histopathologic-cancer-detection/base_dir' # <-------------change the name for run2 and run3\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "# train_dir\n",
    "train_dir = os.path.join(base_dir, 'train_dir')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "# val_dir\n",
    "val_dir = os.path.join(base_dir, 'val_dir')\n",
    "os.mkdir(val_dir)\n",
    "\n",
    "# create new folders inside train_dir\n",
    "no_tumor_tissue = os.path.join(train_dir, 'a_no_tumor_tissue')\n",
    "os.mkdir(no_tumor_tissue)\n",
    "has_tumor_tissue = os.path.join(train_dir, 'b_has_tumor_tissue')\n",
    "os.mkdir(has_tumor_tissue)\n",
    "\n",
    "\n",
    "# create new folders inside val_dir\n",
    "no_tumor_tissue = os.path.join(val_dir, 'a_no_tumor_tissue')\n",
    "os.mkdir(no_tumor_tissue)\n",
    "has_tumor_tissue = os.path.join(val_dir, 'b_has_tumor_tissue')\n",
    "os.mkdir(has_tumor_tissue)\n",
    "\n",
    "# Set the ID of each image to be the index of table\n",
    "df_data.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transfer train/test images to created folder\n",
    "# Get a list of train and val images\n",
    "train_list = list(df_train['id'])\n",
    "val_list = list(df_val['id'])\n",
    "\n",
    "\n",
    "# Transfer the training images\n",
    "for image in train_list:\n",
    "    \n",
    "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
    "    fname = image + '.tif'\n",
    "    # get the label for a certain image\n",
    "    target = df_data.loc[image,'label']\n",
    "    \n",
    "    # these must match the folder names\n",
    "    if target == 0:\n",
    "        label = 'a_no_tumor_tissue'\n",
    "    if target == 1:\n",
    "        label = 'b_has_tumor_tissue'\n",
    "    \n",
    "    # source path to image\n",
    "    src = os.path.join('histopathologic-cancer-detection/train/', fname)\n",
    "    # destination path to image\n",
    "    dst = os.path.join(train_dir, label, fname)\n",
    "    # copy the image from the source to the destination\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "# Transfer the validation images\n",
    "for image in val_list:\n",
    "    \n",
    "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
    "    fname = image + '.tif'\n",
    "    # get the label for a certain image\n",
    "    target = df_data.loc[image,'label']\n",
    "    \n",
    "    # these must match the folder names\n",
    "    if target == 0:\n",
    "        label = 'a_no_tumor_tissue'\n",
    "    if target == 1:\n",
    "        label = 'b_has_tumor_tissue'\n",
    "    \n",
    "\n",
    "    # source path to image\n",
    "    src = os.path.join('histopathologic-cancer-detection/train/', fname)\n",
    "    # destination path to image\n",
    "    dst = os.path.join(val_dir, label, fname)\n",
    "    # copy the image from the source to the destination\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>The code below here provides a function to filter the copied images in training/validation folder and re-write them under same directory</br>\n",
    "<br>Run the code below only for model 2 or 3 each time after the previous steps</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For Model 2 only\n",
    "\n",
    "#Augement all the training/testing sets in linear filter\n",
    "aug_base_dir = 'histopathologic-cancer-detection/augement_1/'\n",
    "aug_train_dir_1 = aug_base_dir + '/train_dir/a_no_tumor_tissue'\n",
    "aug_train_dir_2 = aug_base_dir + '/train_dir/b_has_tumor_tissue'\n",
    "aug_val_dir_1 = aug_base_dir + '/val_dir/a_no_tumor_tissue'\n",
    "aug_val_dir_2 = aug_base_dir + '/val_dir/b_has_tumor_tissue'\n",
    "\n",
    "def augment_dir(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            new_img = apply(img, 'blur_sharp')\n",
    "            cv2.imwrite(os.path.join(folder,filename), new_img)\n",
    "\n",
    "#Augment and write back all images for given directory   \n",
    "augment_dir(aug_train_dir_1)\n",
    "augment_dir(aug_train_dir_2)\n",
    "augment_dir(aug_val_dir_1)\n",
    "augment_dir(aug_val_dir_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Model 3 only\n",
    "#apply half Gaussian filter and half bright-contrast filter to training dataset\n",
    "def augment_dir(folder):\n",
    "    i = 1\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            if i % 2 == 0: \n",
    "                new_img = apply(img, 'weighted_filter')\n",
    "            else:\n",
    "                new_img = apply(img, 'bright_contrast')\n",
    "            cv2.imwrite(os.path.join(folder,filename), new_img)\n",
    "            i = i + 1\n",
    "\n",
    "#Augment and write back all images for given directory   \n",
    "augment_dir(aug_train_dir_1)\n",
    "augment_dir(aug_train_dir_2)\n",
    "augment_dir(aug_val_dir_1)\n",
    "augment_dir(aug_val_dir_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Build CNN Model</H4>\n",
    "<br>The layers and paramters chose here are inspired by the <a href=\"https://www.kaggle.com/vbookshelf/cnn-how-to-use-160-000-images-without-crashing\">kernal by Marsh</a>, which is ideal in dealing with this particular dataset</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Base Model (with original images)\n",
    "train_path = 'histopathologic-cancer-detection/base_dir/train_dir' # <----------------Change the dir for run2 and run3\n",
    "valid_path = 'histopathologic-cancer-detection/base_dir/val_dir'   # <----------------Change the dir for run2 and run3\n",
    "test_path = 'histopathologic-cancer-detection/test'                \n",
    "\n",
    "num_train_samples = len(df_train)\n",
    "num_val_samples = len(df_val)\n",
    "\n",
    "# Define the batch size and steps\n",
    "train_batch_size = 10\n",
    "val_batch_size = 10\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size) \n",
    "val_steps = np.ceil(num_val_samples / val_batch_size) \n",
    "\n",
    "### Generators\n",
    "datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "IMAGE_SIZE = 96                                                  # <----------------Change size to be 94 for run2 and run3\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "train_gen = datagen.flow_from_directory(train_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=train_batch_size,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "val_gen = datagen.flow_from_directory(valid_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=val_batch_size,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "test_gen = datagen.flow_from_directory(valid_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=1,\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=False)\n",
    "\n",
    "### Building Convolutional Neural Networks (CNN)\n",
    "#Parameters\n",
    "kernel_size = (3,3)\n",
    "pool_size= (2,2)\n",
    "first_filters = 32\n",
    "second_filters = 64\n",
    "third_filters = 128\n",
    "\n",
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.3\n",
    "\n",
    "#Build Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (96, 96, 3)))  # <----Change to (94,94,3) for run2 and run3\n",
    "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
    "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = pool_size)) \n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
    "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
    "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
    "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
    "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(dropout_dense))\n",
    "model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/parameters.png\" alt=\"Paramters\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train the model\n",
    "model.compile(Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "filepath = \"histopathologic-cancer-detection/model_1\"  # <----------------Change dir for saving model for run2 and run3\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, \n",
    "                                   verbose=1, mode='max', min_lr=0.00001)\n",
    "                              \n",
    "                              \n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "#Get the history log of each step (10) of batches (9000) for training set######\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=20, verbose=1,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>History Log Outputs for Model 1, 2 and 3</H4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Model 1 (Original Image)</br>\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/epoch_2.png\" alt=\"epoch_2\">\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/epoch_3.png\" alt=\"epoch_3\">\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/epoch_19.png\" alt=\"epoch_19\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Model 2 (Linear-Filtered Image)</br>\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/epoch_1(2).png\" alt=\"epoch_1(2)\">\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/epoch_2(2).png\" alt=\"epoch_2(2)\">\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/epoch_20(2).png\" alt=\"epoch_20(2)\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Model 3 (Gaussian/White/Contrast Image)</br>\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/epoch_1(3).png\" alt=\"epoch_1(3)\">\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image//epoch_2(3).png\" alt=\"epoch_2(3)\">\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/epoch_20(3).png\" alt=\"epoch_20(3)\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Model Evaluation</H3>\n",
    "<br>This section contains code for evaluating the results of our trained CNN to test dataset from three models, which consists of:</br>\n",
    "<ol>\n",
    "  <li>Accuracy and Loss</li>\n",
    "  <li>Prediction Accuracy</li>\n",
    "  <li>AUC Score</li>\n",
    "  <li>Confusion Matrix</li>\n",
    "</ol> \n",
    "<br>Note: The parameters for loading the saved model need to be changed for comparing the results of three different models</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Accuracy and loss</H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get accuracy and loss numerical values\n",
    "model.metrics_names\n",
    "model.load_weights('histopathologic-cancer-detection/model_1') #<-----------------Change the name for loading model 2 or 3\n",
    "\n",
    "val_loss, val_acc = \\\n",
    "model.evaluate_generator(test_gen, \n",
    "                        steps=len(df_val))\n",
    "\n",
    "print('val_loss:', val_loss)\n",
    "print('val_acc:', val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Results for Model 1 (Original)</br>\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/loss_acc_1.png\" alt=\"loss_acc_1\">\n",
    "\n",
    "<br>Results for Model 2 (Linear-Filtered Image)</br>\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/loss_acc_2.png\" alt=\"loss_acc_2\">\n",
    "\n",
    "<br>Results for Model 3 (Gaussian/White/Contrast Image)</br>\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/loss_acc_3.png\" alt=\"loss_acc_3\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy and loss\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss of original dataset')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy of original dataset')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Results for Model 1 (Original)</br>\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/loss_1.png\" alt=\"loss_1\" width=\"600px\" height=\"450px\">\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/accuracy_1.png\" alt=\"accuracy_1\" width=\"600px\" height=\"450px\">\n",
    "\n",
    "<br>Results for Model 2 (Linear-Filtered Image)</br>\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/loss_3.png\" alt=\"loss_2\" width=\"600px\" height=\"450px\">\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/accuracy_3.png\" alt=\"accuracy_2\" width=\"600px\" height=\"450px\">\n",
    "\n",
    "<br>Results for Model 3 (Gaussian/White/Contrast Image)</br>\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/loss_2.png\" alt=\"loss_3\" width=\"600px\" height=\"450px\">\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/accuracy_2.png\" alt=\"accuracy_3\" width=\"600px\" height=\"450px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Prediction Accuracy</H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "predictions = model.predict_generator(test_gen, steps=len(df_val), verbose=1)\n",
    "df_preds = pd.DataFrame(predictions, columns=['no_tumor_tissue', 'has_tumor_tissue'])\n",
    "\n",
    "# Get the true labels\n",
    "y_true = test_gen.classes\n",
    "\n",
    "# Get the predicted labels as probabilities\n",
    "y_pred = df_preds['has_tumor_tissue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>AUC Score</H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC\n",
    "roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Loss, Accuracy and AUC Score of Three Different Datasets</br>\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/result_table.png\" alt=\"table\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Confusion Matrix</H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "test_labels = test_gen.classes\n",
    "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))\n",
    "cm_plot_labels = ['no_tumor_tissue', 'has_tumor_tissue']\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Results for Model 1 (Original)</br>\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/cm_11.png\" alt=\"cm_1\" width=\"400px\" height=\"350px\">\n",
    "\n",
    "<br>Results for Model 2 (Linear-Filtered Image)</br>\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/cm_22.png\" alt=\"cm_2\" width=\"400px\" height=\"350px\">\n",
    "\n",
    "<br>Results for Model 3 (Gaussian/White/Contrast Image)</br>\n",
    "<img src=\"https://raw.githubusercontent.com/BoyangW/histopathologic-cancer-detection/master/image/cm_33.png\" alt=\"cm_3\" width=\"400px\" height=\"350px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Conclusion</H3>\n",
    "<br>Among all three different preprocessed dataset,  data augmented with linear filter tend to have best test accuracy given the same CNN model</br>\n",
    "<br>These results confirmed our hypothesis that augmentation not only helps reduce overfitting chance, but also optimizes the training/testing error to some extends</br>\n",
    "\n",
    "<H4>Insights</H4>\n",
    "<ol>\n",
    "  <li>Choosing the right augmentation methods/filters depend on the types of images and questions we have</li>\n",
    "  <li>There’s no universal answer to solve every problem and parameters for filtering and training the model</li>\n",
    "  <li>Domain knowledge, combined with trial and error are important for optimizing the results with contents</li>\n",
    "  <li>Larger dataset could be used to generate more accurate result from this kernel</li>\n",
    "</ol> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
